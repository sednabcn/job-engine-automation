name: Unified Reverse Job Enginee
# ===============================================================
# üöÄ UNIFIED REVERSE JOB ENGINE ‚Äì ENHANCED WITH FULL AUTOMATION
# ===============================================================

on:
  schedule:
    - cron: '0 9,21 * * *'  # 9 AM and 9 PM daily - runs daily_report
  
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        type: choice
        default: 'daily_report'
        options:
          - daily_report
          - full_analysis
          - batch_analysis
          - start_sprint
          - log_daily
          - end_sprint
          - quality_check
          - generate_materials
          - complete_flow              # NEW: Option A - Run full lifecycle
          - auto_sprint_cycle          # NEW: Auto start‚Üílog‚Üíend sprint
      
      cv_path:
        description: 'Path to CV file (.txt, .pdf, .docx)'
        required: false
        default: 'data/my_cv.pdf'
      
      job_path:
        description: 'Path to job description OR comma-separated files for batch'
        required: false
        default: 'data/target_job.pdf'
      
      job_metadata:
        description: 'Job title and company (format: "Title|Company")'
        required: false
        default: 'Target Role|Target Company'
      
      sprint_data:
        description: 'Sprint data as JSON: {"hours":3,"concepts":["skill"],"notes":"text","project_url":"url","test_scores":{}}'
        required: false
        default: '{"hours":3,"concepts":[],"notes":"","project_url":"","test_scores":{}}'
      
      options:
        description: 'Options: generate_materials,generate_comparison,send_email,chain_next (comma-separated)'
        required: false
        default: 'generate_materials'
      
      email_to:
        description: 'Email address for notifications'
        required: false
        default: ''
  
  push:
    paths:
      - 'data/**.pdf'
      - 'data/**.docx'
      - 'data/**.txt'

env:
  PYTHON_VERSION: '3.11'
  PYTHONPATH: 'src'
  DATA_DIR: 'job_search_data'
  STATE_ARTIFACT: 'job-search-state-v1'
  TARGET_SCORE: 90

jobs:
  ultimate_job_search:
    name: Ultimate Job Search Engine
    runs-on: ubuntu-latest
    
    steps:
      # =====================================================================
      # SETUP & INITIALIZATION
      # =====================================================================
      
      - name: üì• Checkout repository
        uses: actions/checkout@v4
      
      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install dependencies
        run: |
          pip install --upgrade pip
          pip install python-dateutil PyPDF2 python-docx
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          echo "‚úÖ Dependencies installed"
      
      - name: üìÇ Ensure directories exist
        run: |
          mkdir -p ${{ env.DATA_DIR }}
          mkdir -p data
          mkdir -p src
          mkdir -p output
          mkdir -p batch_results
          
          if [ ! -f "src/python_advanced_job_engine.py" ]; then
            echo "‚ùå Error: src/python_advanced_job_engine.py not found"
            exit 1
          fi
          
          echo "‚úÖ Directories created and verified"
      
      # ========================================
      # RESTORE STATE FROM PREVIOUS RUNS
      # ========================================
      
      - name: üì• Restore State from Artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.STATE_ARTIFACT }}
          path: ${{ env.DATA_DIR }}
        continue-on-error: true
      
      - name: üîç Verify State Restoration
        id: verify_state
        run: |
          if [ -f "${{ env.DATA_DIR }}/workflow_state.json" ]; then
            echo "‚úÖ State restored from previous run"
            echo "state_restored=true" >> $GITHUB_OUTPUT
          else
            echo "‚ÑπÔ∏è  First run - starting fresh (this is normal)"
            echo "state_restored=false" >> $GITHUB_OUTPUT
          fi
      
      # =====================================================================
      # VALIDATE INPUTS
      # =====================================================================
      
      - name: ‚úÖ Validate Inputs
        id: validate
        run: |
          # Parse consolidated inputs
          JOB_METADATA="${{ github.event.inputs.job_metadata }}"
          if [[ "$JOB_METADATA" == *"|"* ]]; then
            JOB_TITLE="${JOB_METADATA%%|*}"
            COMPANY_NAME="${JOB_METADATA##*|}"
          else
            JOB_TITLE="Target Role"
            COMPANY_NAME="Target Company"
          fi
          
          OPTIONS="${{ github.event.inputs.options }}"
          
          ACTION="${{ github.event.inputs.action }}"
          CV_PATH="${{ github.event.inputs.cv_path }}"
          JOB_PATH="${{ github.event.inputs.job_path }}"
          
          echo "üîç Validating inputs for action: $ACTION"
          
          # Validate based on action
          case "$ACTION" in
            "full_analysis"|"complete_flow")
              if [ ! -f "$CV_PATH" ]; then
                echo "‚ùå CV file not found: $CV_PATH"
                exit 1
              fi
              if [ ! -f "$JOB_PATH" ]; then
                echo "‚ùå Job file not found: $JOB_PATH"
                exit 1
              fi
              echo "‚úÖ Files validated"
              ;;
            
            "batch_analysis")
              if [ ! -f "$CV_PATH" ]; then
                echo "‚ùå CV file not found: $CV_PATH"
                exit 1
              fi
              if [[ "$JOB_PATH" != *","* ]]; then
                if [ ! -f "$JOB_PATH" ]; then
                  echo "‚ùå Job file not found: $JOB_PATH"
                  exit 1
                fi
              else
                IFS=',' read -ra FILES <<< "$JOB_PATH"
                for file in "${FILES[@]}"; do
                  file=$(echo "$file" | xargs)
                  if [ ! -f "$file" ]; then
                    echo "‚ùå Job file not found: $file"
                    exit 1
                  fi
                done
              fi
              echo "‚úÖ All batch files validated"
              ;;
          esac
          
          echo "validation_passed=true" >> $GITHUB_OUTPUT
      
      # =====================================================================
      # INITIALIZE ENGINE
      # =====================================================================
      
      - name: üîß Initialize Engine
        id: init_engine
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              state = engine.state
              
              current_score = state.get('current_score', 0)
              baseline_score = state.get('baseline_score', 0)
              current_sprint = state.get('current_sprint', 0)
              mode = state.get('mode') or 'none'
              initialized = 'true' if (mode and mode != 'none') else 'false'
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"current_score={current_score}\n")
                  f.write(f"baseline_score={baseline_score}\n")
                  f.write(f"current_sprint={current_sprint}\n")
                  f.write(f"mode={mode}\n")
                  f.write(f"initialized={initialized}\n")
              
              print(f"‚úÖ Engine initialized")
              print(f"   Score: {current_score}% | Mode: {mode} | Initialized: {initialized}")
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # OPTION A: COMPLETE FLOW - Run entire lifecycle automatically
      # ===================================================================
      
      - name: üöÄ Complete Flow - Full Lifecycle
        if: github.event.inputs.action == 'complete_flow'
        id: complete_flow
        run: |
          python << 'PYTHON_EOF'
          import os, sys, json
          from datetime import datetime
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              cv_path = "${{ github.event.inputs.cv_path }}"
              job_path = "${{ github.event.inputs.job_path }}"
              
              job_metadata = "${{ github.event.inputs.job_metadata }}"
              if '|' in job_metadata:
                  job_title, company = job_metadata.split('|', 1)
              else:
                  job_title = "Target Role"
                  company = "Target Company"
              
              print("\n" + "="*80)
              print("üöÄ COMPLETE FLOW - FULL LIFECYCLE AUTOMATION")
              print("="*80)
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              # STEP 1: Full Analysis
              print("\n" + "="*60)
              print("STEP 1/5: Full Job Analysis")
              print("="*60)
              
              analysis = engine.analyze_from_files(
                  cv_file=cv_path,
                  job_file=job_path,
                  job_title=job_title,
                  company=company
              )
              
              score = analysis['score']['total_score']
              print(f"‚úÖ Match Score: {score}%")
              
              # STEP 2: Create Learning Plan
              print("\n" + "="*60)
              print("STEP 2/5: Create Learning Plan (REVERSE mode)")
              print("="*60)
              
              learning_plan = engine.create_learning_plan(analysis, mode="reverse")
              print(f"‚úÖ Plan created - Timeline: {learning_plan['estimated_duration']}")
              
              # STEP 3: Create Improvement Strategy
              print("\n" + "="*60)
              print("STEP 3/5: Create Improvement Strategy")
              print("="*60)
              
              strategy = engine.create_improvement_strategy(analysis, learning_plan)
              print("‚úÖ Strategy generated")
              
              # STEP 4: Generate Skill Tests
              print("\n" + "="*60)
              print("STEP 4/5: Generate Skill Tests")
              print("="*60)
              
              missing_skills = analysis['gaps']['missing_required_skills'][:5]
              tests = engine.generate_skill_tests(missing_skills)
              print(f"‚úÖ Generated tests for {len(missing_skills)} skills")
              
              # STEP 5: Generate Application Materials
              print("\n" + "="*60)
              print("STEP 5/5: Generate Application Materials")
              print("="*60)
              
              letters = engine.generate_recruiter_letter(analysis, learning_plan)
              print("‚úÖ Cover letters and materials generated")
              
              # Update state
              engine.state['baseline_score'] = score
              engine.state['current_score'] = score
              engine.state['mode'] = 'reverse'
              engine.state['current_stage'] = 'baseline'
              engine.state['complete_flow_run'] = datetime.now().isoformat()
              engine._save_json(engine.state_file, engine.state)
              
              print("\n" + "="*80)
              print("‚úÖ COMPLETE FLOW FINISHED!")
              print("="*80)
              print(f"\nüìä Results:")
              print(f"   Match Score: {score}%")
              print(f"   Missing Skills: {len(analysis['gaps']['missing_required_skills'])}")
              print(f"   Timeline: {learning_plan['estimated_duration']}")
              print(f"   All materials generated in: {engine.data_dir}")
              print(f"\nüéØ Next Step: Start your first sprint with 'start_sprint' action")
              print("="*80)
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"flow_completed=true\n")
                  f.write(f"score={score}\n")
                  f.write(f"next_action=start_sprint\n")
              
          except Exception as e:
              print(f"‚ùå Error in complete flow: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # OPTION A: AUTO SPRINT CYCLE - Automated sprint management
      # ===================================================================
      
      - name: üîÑ Auto Sprint Cycle
        if: github.event.inputs.action == 'auto_sprint_cycle'
        id: auto_sprint
        run: |
          python << 'PYTHON_EOF'
          import os, sys, json
          from datetime import datetime
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if engine.state.get('mode') is None:
                  print("‚ùå Workflow not initialized. Run 'full_analysis' or 'complete_flow' first.")
                  exit(1)
              
              print("\n" + "="*80)
              print("üîÑ AUTO SPRINT CYCLE")
              print("="*80)
              
              # Check if there's an active sprint
              active_sprint = None
              if engine.sprint_history:
                  last = engine.sprint_history[-1]
                  if isinstance(last, dict) and not last.get('completed'):
                      active_sprint = last
              
              sprint_data_str = "${{ github.event.inputs.sprint_data }}"
              sprint_data = json.loads(sprint_data_str) if sprint_data_str else {}
              
              if active_sprint:
                  # Log daily progress
                  days_logged = len(active_sprint.get('daily_logs', []))
                  print(f"\nüìù Active Sprint {active_sprint['sprint_number']} - Day {days_logged}/14")
                  
                  hours = float(sprint_data.get('hours', 3))
                  concepts = sprint_data.get('concepts', ['Daily progress'])
                  notes = sprint_data.get('notes', 'Auto-logged progress')
                  
                  engine.log_daily(hours, concepts, notes)
                  print(f"‚úÖ Logged {hours}h with {len(concepts)} concepts")
                  
                  # Check if sprint should end (14 days or project URL provided)
                  project_url = sprint_data.get('project_url', '')
                  if days_logged >= 13 or project_url:
                      print(f"\nüèÅ Ending Sprint {active_sprint['sprint_number']}")
                      
                      if not project_url:
                          project_url = "https://github.com/user/auto-sprint-project"
                      
                      test_scores = sprint_data.get('test_scores', {})
                      if not test_scores:
                          test_scores = {
                              skill: 70.0 
                              for skill in active_sprint['skills_targeted']
                          }
                      
                      result = engine.end_sprint(project_url, test_scores)
                      print("‚úÖ Sprint completed!")
                      
                      with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                          f.write("sprint_completed=true\n")
                          f.write("next_action=start_sprint\n")
                  else:
                      with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                          f.write("sprint_completed=false\n")
                          f.write("next_action=auto_sprint_cycle\n")
              
              else:
                  # Start new sprint
                  print("\nüöÄ Starting New Sprint")
                  
                  if not engine.learning_progress:
                      print("‚ùå No learning plan found. Run 'full_analysis' first.")
                      exit(1)
                  
                  plan = engine.learning_progress[-1] if isinstance(engine.learning_progress, list) else engine.learning_progress
                  
                  skills_to_learn = []
                  mastered_lower = [s.lower() for s in engine.state.get('skills_mastered', [])]
                  
                  for item in plan['levels']['study']:
                      if item['skill'].lower() not in mastered_lower:
                          skills_to_learn.append(item['skill'])
                          if len(skills_to_learn) >= 2:
                              break
                  
                  if not skills_to_learn:
                      for item in plan['levels']['practice']:
                          if item['skill'].lower() not in mastered_lower:
                              skills_to_learn.append(item['skill'])
                              if len(skills_to_learn) >= 2:
                                  break
                  
                  if not skills_to_learn:
                      print("üéâ All skills mastered!")
                      with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                          f.write("all_skills_mastered=true\n")
                      exit(0)
                  
                  project_goal = f"Build project demonstrating {' and '.join(skills_to_learn)}"
                  sprint = engine.start_sprint(skills_to_learn, project_goal)
                  
                  print(f"‚úÖ Sprint {sprint['sprint_number']} started!")
                  print(f"   Skills: {', '.join(skills_to_learn)}")
                  print(f"   Goal: {project_goal}")
                  
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write("sprint_started=true\n")
                      f.write("next_action=auto_sprint_cycle\n")
              
              print("\n" + "="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # DAILY PROGRESS REPORT
      # ===================================================================
      
      - name: üìä Daily Progress Report
        if: |
          (github.event_name == 'schedule') || 
          (github.event.inputs.action == 'daily_report')
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          from datetime import datetime
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if engine.state.get('mode') is None:
                  print("\n" + "="*80)
                  print("‚ö†Ô∏è  WORKFLOW NOT INITIALIZED")
                  print("="*80)
                  print("\nüìã To get started:")
                  print("   Option 1: Run 'complete_flow' - Full automated setup")
                  print("   Option 2: Run 'full_analysis' - Manual step-by-step")
                  print("\n" + "="*80)
                  exit(0)
              
              print("\n" + "="*80)
              print(f"üìä DAILY PROGRESS REPORT - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
              print("="*80)
              
              engine.display_progress_dashboard()
              
              if engine.sprint_history:
                  last_sprint = engine.sprint_history[-1]
                  if isinstance(last_sprint, dict) and not last_sprint.get('completed', False):
                      days_logged = len(last_sprint.get('daily_logs', []))
                      print(f"\n‚è∞ SPRINT REMINDER:")
                      print(f"   Sprint {last_sprint['sprint_number']}: Day {days_logged}/14")
                      print(f"   üí° Tip: Use 'auto_sprint_cycle' to automate daily logging!")
              
              print("\n" + "="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # FULL JOB ANALYSIS (Individual step)
      # ===================================================================
      
      - name: üéØ Full Job Analysis
        if: github.event.inputs.action == 'full_analysis'
        id: full_analysis
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              cv_path = "${{ github.event.inputs.cv_path }}"
              job_path = "${{ github.event.inputs.job_path }}"
              
              job_metadata = "${{ github.event.inputs.job_metadata }}"
              if '|' in job_metadata:
                  job_title, company = job_metadata.split('|', 1)
              else:
                  job_title = "Target Role"
                  company = "Target Company"
              
              print("\n" + "="*80)
              print("üéØ FULL JOB ANALYSIS")
              print("="*80)
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              print(f"\nüìÑ Analyzing CV: {cv_path}")
              print(f"üìÑ Against Job: {job_path}")
              print(f"üè¢ Company: {company}")
              print(f"üíº Role: {job_title}")
              
              analysis = engine.analyze_from_files(
                  cv_file=cv_path,
                  job_file=job_path,
                  job_title=job_title,
                  company=company
              )
              
              score = analysis['score']['total_score']
              
              print("\nüìö Creating learning plan (REVERSE mode)...")
              learning_plan = engine.create_learning_plan(analysis, mode="reverse")
              
              print("üéØ Creating improvement strategy...")
              strategy = engine.create_improvement_strategy(analysis, learning_plan)
              
              print("üìù Generating skill tests...")
              missing_skills = analysis['gaps']['missing_required_skills'][:5]
              tests = engine.generate_skill_tests(missing_skills)
              
              # Generate materials if requested
              options_str = "${{ github.event.inputs.options }}"
              options = [opt.strip() for opt in options_str.split(',') if opt.strip()]
              
              if 'generate_materials' in options:
                  print("\n‚úâÔ∏è  Generating application materials...")
                  letters = engine.generate_recruiter_letter(analysis, learning_plan)
              
              # Update state
              engine.state['baseline_score'] = score
              engine.state['current_score'] = score
              engine.state['mode'] = 'reverse'
              engine.state['current_stage'] = 'baseline'
              engine._save_json(engine.state_file, engine.state)
              
              print("\n" + "="*80)
              print("‚úÖ ANALYSIS COMPLETE")
              print("="*80)
              print(f"\nüìä Match Score: {score}%")
              print(f"üìã Missing Skills: {len(analysis['gaps']['missing_required_skills'])}")
              print(f"‚è±Ô∏è  Timeline: {learning_plan['estimated_duration']}")
              print(f"\n‚úÖ All data saved to: {engine.data_dir}")
              print(f"\nüöÄ Next Steps:")
              print(f"   ‚Ä¢ Use 'auto_sprint_cycle' for automated learning")
              print(f"   ‚Ä¢ Or 'start_sprint' for manual control")
              print("="*80)
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"score={score}\n")
                  f.write(f"missing_skills={len(analysis['gaps']['missing_required_skills'])}\n")
                  f.write(f"timeline={learning_plan['estimated_duration']}\n")
              
          except FileNotFoundError as e:
              print(f"\n‚ùå File not found: {e}")
              exit(1)
          except Exception as e:
              print(f"\n‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # BATCH JOB ANALYSIS
      # ===================================================================
      
      - name: üìä Batch Job Analysis
        if: github.event.inputs.action == 'batch_analysis'
        id: batch_analysis
        run: |
          python << 'PYTHON_EOF'
          import os, sys, json
          from datetime import datetime
          from pathlib import Path
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              cv_file = "${{ github.event.inputs.cv_path }}"
              job_files_input = "${{ github.event.inputs.job_path }}"
              
              options_str = "${{ github.event.inputs.options }}"
              options = [opt.strip() for opt in options_str.split(',') if opt.strip()]
              generate_comparison = 'generate_comparison' in options
              
              job_files = [f.strip() for f in job_files_input.split(',') if f.strip()]
              
              print("\n" + "="*80)
              print("üìä BATCH JOB ANALYSIS")
              print("="*80)
              print(f"\nüìÑ CV: {cv_file}")
              print(f"üéØ Jobs: {len(job_files)}")
              print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
              
              results = []
              
              for idx, job_file in enumerate(job_files, 1):
                  print(f"\n{'='*60}")
                  print(f"üìã Job {idx}/{len(job_files)}: {job_file}")
                  print(f"{'='*60}")
                  
                  try:
                      analysis = engine.analyze_from_files(
                          cv_file=cv_file,
                          job_file=job_file
                      )
                      
                      job_id = analysis['job_id']
                      score = analysis['score']['total_score']
                      
                      job_dir = f"batch_results/{job_id}"
                      os.makedirs(job_dir, exist_ok=True)
                      
                      with open(f"{job_dir}/match_score.json", 'w') as f:
                          json.dump(analysis['score'], f, indent=2)
                      
                      with open(f"{job_dir}/gap_analysis.json", 'w') as f:
                          json.dump(analysis['gaps'], f, indent=2)
                      
                      learning_plan = engine.create_learning_plan(analysis)
                      with open(f"{job_dir}/learning_plan.json", 'w') as f:
                          json.dump(learning_plan, f, indent=2)
                      
                      strategy = engine.create_improvement_strategy(analysis, learning_plan)
                      with open(f"{job_dir}/improvement_strategy.md", 'w') as f:
                          f.write(strategy)
                      
                      results.append({
                          'job_file': job_file,
                          'job_id': job_id,
                          'score': score,
                          'breakdown': analysis['score']['breakdown'],
                          'missing_skills': len(analysis['gaps']['missing_required_skills']),
                          'status': 'success'
                      })
                      
                      print(f"‚úÖ Score: {score}% - Saved to {job_dir}/")
                      
                  except Exception as e:
                      print(f"‚ùå Error: {str(e)}")
                      results.append({
                          'job_file': job_file,
                          'score': 0,
                          'status': 'error',
                          'error': str(e)
                      })
              
              if generate_comparison and len(results) > 1:
                  print("\nüìä Generating comparison report...")
                  
                  sorted_results = sorted(
                      [r for r in results if r['status'] == 'success'],
                      key=lambda x: x['score'],
                      reverse=True
                  )
                  
                  report = f"""# Batch Job Analysis Comparison Report

              **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
              **CV Analyzed:** {cv_file}
              **Total Jobs:** {len(results)}

              ---

              ## Summary Ranking

              """
                  
                  for rank, result in enumerate(sorted_results, 1):
                      emoji = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â" if rank == 3 else f"{rank}."
                      status = "‚úÖ Apply Now" if result['score'] >= 75 else "‚ö†Ô∏è Improve First" if result['score'] >= 60 else "‚ùå Major Gaps"
                      
                      report += f"{emoji} **{result['job_id']}** - {result['score']}% - {status}\n"
                      report += f"   - File: `{result['job_file']}`\n"
                      report += f"   - Missing Skills: {result['missing_skills']}\n\n"
                  
                  with open('batch_results/comparison_report.md', 'w') as f:
                      f.write(report)
                  
                  print("‚úÖ Comparison report generated!")
              
              with open('batch_results/summary.json', 'w') as f:
                  json.dump(results, f, indent=2)
              
              successful = [r for r in results if r['status'] == 'success']
              if successful:
                  avg_score = sum(r['score'] for r in successful) / len(successful)
                  best_score = max(r['score'] for r in successful)
                  best_job = sorted_results[0]['job_id'] if sorted_results else 'N/A'
              else:
                  avg_score = 0
                  best_score = 0
                  best_job = 'N/A'
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"total_jobs={len(job_files)}\n")
                  f.write(f"successful={len(successful)}\n")
                  f.write(f"average_score={avg_score:.1f}\n")
                  f.write(f"best_score={best_score:.1f}\n")
                  f.write(f"best_job={best_job}\n")
              
              print(f"\n‚úÖ Batch analysis complete!")
              print(f"üìä Average Score: {avg_score:.1f}%")
              print(f"üèÜ Best Score: {best_score:.1f}%")
              print("="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # START SPRINT (Individual step)
      # ===================================================================
      
      - name: üèÉ Start Sprint
        if: github.event.inputs.action == 'start_sprint'
        run: |
          python << 'PYTHON_EOF'
          import sys
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if engine.state.get('mode') is None:
                  print("‚ùå Workflow not initialized. Run 'full_analysis' or 'complete_flow' first.")
                  exit(1)
              
              if not engine.learning_progress:
                  print("‚ùå No learning plan found. Run 'full_analysis' first.")
                  exit(1)
              
              plan = engine.learning_progress[-1] if isinstance(engine.learning_progress, list) else engine.learning_progress
              
              skills_to_learn = []
              mastered_lower = [s.lower() for s in engine.state.get('skills_mastered', [])]
              
              for item in plan['levels']['study']:
                  if item['skill'].lower() not in mastered_lower:
                      skills_to_learn.append(item['skill'])
                      if len(skills_to_learn) >= 2:
                          break
              
              if not skills_to_learn:
                  for item in plan['levels']['practice']:
                      if item['skill'].lower() not in mastered_lower:
                          skills_to_learn.append(item['skill'])
                          if len(skills_to_learn) >= 2:
                              break
              
              if not skills_to_learn:
                  print("üéâ All planned skills mastered!")
                  exit(0)
              
              project_goal = f"Build project demonstrating {' and '.join(skills_to_learn)}"
              
              sprint = engine.start_sprint(skills_to_learn, project_goal)
              
              print("\nüí° Next Steps:")
              print("   ‚Ä¢ Use 'auto_sprint_cycle' to automate daily logging")
              print("   ‚Ä¢ Or use 'log_daily' for manual daily updates")
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # LOG DAILY PROGRESS (Individual step)
      # ===================================================================     
      - name: üìù Log Daily Progress
        if: github.event.inputs.action == 'log_daily'
        run: |
          python << 'PYTHON_EOF'
          import sys, json
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if not engine.sprint_history:
                  print("‚ùå No active sprint. Start a sprint first.")
                  exit(1)
              
              last_sprint = engine.sprint_history[-1]
              if not isinstance(last_sprint, dict) or last_sprint.get('completed', False):
                  print("‚ùå No active sprint. Current sprint is completed.")
                  exit(1)
              
              sprint_data_str = "${{ github.event.inputs.sprint_data }}"
              sprint_data = json.loads(sprint_data_str) if sprint_data_str else {}
              
              hours = float(sprint_data.get('hours', 3))
              concepts = sprint_data.get('concepts', [])
              notes = sprint_data.get('notes', '')
              
              if not concepts:
                  concepts = ["Daily learning progress"]
              
              engine.log_daily(hours, concepts, notes)
              
              print(f"\n‚úÖ Successfully logged {hours}h with {len(concepts)} concepts")
              print(f"\nüí° Tip: Use 'auto_sprint_cycle' to automate this process!")
              
          except ValueError as e:
              print(f"‚ùå Invalid hours value: {e}")
              exit(1)
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ===================================================================
      # END SPRINT (Individual step)
      # ===================================================================
      
      - name: üèÅ End Sprint
        if: github.event.inputs.action == 'end_sprint'
        run: |
          python << 'PYTHON_EOF'
          import os, sys, json
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if not engine.sprint_history:
                  print("‚ùå No active sprint found.")
                  exit(1)
              
              current_sprint = engine.sprint_history[-1]
              
              if not isinstance(current_sprint, dict):
                  print("‚ùå Invalid sprint data.")
                  exit(1)
              
              if current_sprint.get('completed', False):
                  print("‚ùå Current sprint already completed.")
                  exit(1)
              
              print("\n" + "="*80)
              print(f"ENDING SPRINT {current_sprint['sprint_number']}")
              print("="*80)
              
              sprint_data_str = "${{ github.event.inputs.sprint_data }}"
              sprint_data = json.loads(sprint_data_str) if sprint_data_str else {}
              
              project_url = sprint_data.get('project_url', '')
              test_scores = sprint_data.get('test_scores', {})
              
              if not project_url:
                  project_url = "https://github.com/user/sprint-project"
                  print("‚ö†Ô∏è  Using default project URL")
              
              if not test_scores or test_scores == {}:
                  test_scores = {
                      skill: 70.0
                      for skill in current_sprint['skills_targeted']
                  }
                  print("‚ö†Ô∏è  Using default test scores (70%)")
              
              result = engine.end_sprint(project_url, test_scores)
              
              cv_path = "${{ github.event.inputs.cv_path }}"
              job_path = "${{ github.event.inputs.job_path }}"
              
              try:
                  print("\nüìÑ Re-analyzing job match...")
                  analysis = engine.analyze_from_files(cv_path, job_path)
                  new_score = analysis['score']['total_score']
                  old_score = engine.state.get('current_score', 0)
                  
                  engine.state['current_score'] = new_score
                  engine._save_json(engine.state_file, engine.state)
                  
                  print(f"\nüìä Score Update:")
                  print(f"   Previous: {old_score}%")
                  print(f"   Current:  {new_score}%")
                  print(f"   Change:   {new_score - old_score:+.1f}%")
              except Exception as e:
                  print(f"‚ö†Ô∏è  Could not re-analyze: {e}")
              
              print("\n" + "="*80)
              
          except json.JSONDecodeError as e:
              print(f"‚ùå Invalid JSON: {e}")
              exit(1)
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # ==================================================================
      # QUALITY GATE CHECK
      # ==================================================================
      
      - name: üö™ Check Quality Gates
        if: |
          (github.event_name == 'schedule') || 
          (github.event.inputs.action == 'quality_check')
        id: quality_gates
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if engine.state.get('mode') is None:
                  print("‚ö†Ô∏è  No workflow initialized")
                  exit(0)
              
              print("\n" + "="*80)
              print("QUALITY GATE ASSESSMENT")
              print("="*80)
              
              gates_status = engine.check_quality_gates()
              
              state = engine.state
              score = state.get('current_score', 0)
              projects = len(state.get('projects_completed', []))
              
              print(f"\nüìä Current Status:")
              print(f"   Match Score: {score}%")
              print(f"   Projects: {projects}")
              print(f"   Skills Mastered: {len(state.get('skills_mastered', []))}")
              
              print(f"\nüö™ Quality Gates:")
              for gate_name, passed in gates_status.items():
                  status = "‚úÖ" if passed else "‚è≥"
                  req = engine.QUALITY_GATES[gate_name]
                  print(f"   {status} {gate_name.upper()}")
                  if "score" in req:
                      print(f"      Score: {score}/{req['score']}%")
                  if "projects" in req:
                      print(f"      Projects: {projects}/{req['projects']}")
              
              if gates_status.get('application_ready', False):
                  print(f"\nüéâ CONGRATULATIONS!")
                  print(f"   You've passed all quality gates!")
                  print(f"   YOU ARE NOW APPLICATION-READY! üöÄ")
                  
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write("application_ready=true\n")
              else:
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write("application_ready=false\n")
              
              print("\n" + "="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # =====================================================================
      # GENERATE APPLICATION MATERIALS
      # =====================================================================
      
      - name: ‚úâÔ∏è Generate Application Materials
        if: github.event.inputs.action == 'generate_materials'
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          from pathlib import Path
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if engine.state.get('mode') is None:
                  print("‚ùå Workflow not initialized. Run 'full_analysis' or 'complete_flow' first.")
                  exit(1)
              
              print("\n" + "="*80)
              print("‚úâÔ∏è  GENERATING APPLICATION MATERIALS")
              print("="*80)
              
              cv_path = "${{ github.event.inputs.cv_path }}"
              job_path = "${{ github.event.inputs.job_path }}"
              
              analysis = engine.analyze_from_files(cv_path, job_path)
              
              if engine.learning_progress:
                  learning_plan = engine.learning_progress[-1] if isinstance(engine.learning_progress, list) else engine.learning_progress
              else:
                  learning_plan = engine.create_learning_plan(analysis, mode="reverse")
              
              print("\nüìù Generating cover letter...")
              letters = engine.generate_recruiter_letter(analysis, learning_plan)
              
              print("\nüìÑ Generating tailored CV highlights...")
              highlights = f"""# CV Highlights for {analysis.get('company', 'Target Company')}

              ## Top Matching Skills
              """
              for skill in analysis['matching']['matched_skills'][:10]:
                  highlights += f"- ‚úÖ {skill}\n"
              
              highlights += f"\n## Key Achievements to Emphasize\n"
              highlights += "- [Add relevant achievements here based on job requirements]\n"
              
              highlights += f"\n## Address These in Interview\n"
              for skill in analysis['gaps']['missing_required_skills'][:5]:
                  highlights += f"- {skill}: [Prepare talking points]\n"
              
              output_dir = Path("output/application_materials")
              output_dir.mkdir(parents=True, exist_ok=True)
              
              (output_dir / "cv_highlights.md").write_text(highlights)
              
              print(f"\n‚úÖ Materials generated in: {output_dir}")
              print("   - Cover letters")
              print("   - CV highlights")
              print("   - Interview preparation notes")
              print("\n" + "="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # =====================================================================
      # SPRINT RECOMMENDATIONS
      # =====================================================================
      
      - name: üí° Generate Sprint Recommendations
        if: steps.init_engine.outputs.initialized == 'true'
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if not engine.sprint_history:
                  print("\nüí° No sprints completed yet.")
                  print("   üí° Tip: Use 'auto_sprint_cycle' for automated sprint management!")
                  exit(0)
              
              completed_sprints = [
                  s for s in engine.sprint_history 
                  if isinstance(s, dict) and s.get('completed')
              ]
              
              if not completed_sprints:
                  print("\n‚è≥ Sprint in progress...")
                  current = engine.sprint_history[-1]
                  if isinstance(current, dict):
                      days_logged = len(current.get('daily_logs', []))
                      print(f"   Sprint {current.get('sprint_number', '?')}: Day {days_logged}/14")
                      print(f"   üí° Tip: Use 'auto_sprint_cycle' to automate daily logging!")
                  exit(0)
              
              last_sprint = completed_sprints[-1]
              
              print("\n" + "="*80)
              print("SPRINT RECOMMENDATIONS")
              print("="*80)
              
              total_hours = last_sprint.get('total_hours', 0)
              
              print(f"\nüìä Last Sprint Performance:")
              print(f"   Total Hours: {total_hours:.1f}h")
              
              state = engine.state
              current_score = state.get('current_score', 0)
              
              print(f"\nüí° Recommendations:")
              
              if current_score < 65:
                  print(f"\nüéØ Next Sprint Focus: FOUNDATION")
                  print(f"   ‚Ä¢ Core Tier 1 skills")
                  print(f"   ‚Ä¢ Basic projects")
              elif current_score < 80:
                  print(f"\nüéØ Next Sprint Focus: SKILL BUILDING")
                  print(f"   ‚Ä¢ Intermediate topics")
                  print(f"   ‚Ä¢ Medium complexity projects")
              elif current_score < 90:
                  print(f"\nüéØ Next Sprint Focus: MASTERY")
                  print(f"   ‚Ä¢ Advanced concepts")
                  print(f"   ‚Ä¢ Production-grade projects")
              else:
                  print(f"\nüéØ Next Focus: POSITIONING")
                  print(f"   ‚Ä¢ Professional branding")
                  print(f"   ‚Ä¢ Network building")
              
              print("\n" + "="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # =====================================================================
      # MILESTONE NOTIFICATIONS
      # =====================================================================
      
      - name: üéâ Check for Milestones
        if: steps.init_engine.outputs.initialized == 'true'
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              state = engine.state
              
              score = state.get('current_score', 0)
              baseline = state.get('baseline_score', 0)
              gates = state.get('quality_gates_passed', [])
              
              milestones = []
              
              if score >= 50 and baseline < 50:
                  milestones.append("üéØ Reached 50% Match Score!")
              if score >= 65 and 'foundation' in gates:
                  milestones.append("üèÜ FOUNDATION GATE PASSED!")
              if score >= 75 and baseline < 75:
                  milestones.append("üéØ Reached 75% Match Score!")
              if score >= 80 and 'competency' in gates:
                  milestones.append("üèÜ COMPETENCY GATE PASSED!")
              if score >= 90 and 'mastery' in gates:
                  milestones.append("üèÜ MASTERY GATE PASSED!")
              
              sprint_count = len([
                  s for s in engine.sprint_history 
                  if isinstance(s, dict) and s.get('completed')
              ])
              if sprint_count == 1:
                  milestones.append("üéä First Sprint Complete!")
              elif sprint_count == 5:
                  milestones.append("üéä Five Sprints Complete!")
              elif sprint_count == 10:
                  milestones.append("üéä Ten Sprints Complete!")
              
              if state.get('application_ready', False):
                  milestones.append("üéâ APPLICATION READY - TIME TO APPLY!")
              
              if milestones:
                  print("\n" + "="*80)
                  print("üéâ MILESTONES ACHIEVED!")
                  print("="*80)
                  for milestone in milestones:
                      print(f"\n   {milestone}")
                  print("\n" + "="*80)
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          PYTHON_EOF
      
      # =====================================================================
      # GENERATE COMPREHENSIVE SUMMARY REPORT
      # =====================================================================
      
      - name: üìÑ Generate Comprehensive Summary Report
        if: always()
        run: |
          python << 'PYTHON_EOF'
          import os, sys
          from datetime import datetime
          from pathlib import Path
          
          try:
              sys.path.insert(0, 'src')
              from python_advanced_job_engine import AdvancedJobEngine
              
              engine = AdvancedJobEngine(data_dir="${{ env.DATA_DIR }}")
              
              if engine.state.get('mode') is None:
                  report_content = f"""# Ultimate Job Search Progress

              **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
              **Status:** Not Initialized

              ---

              ## üöÄ Getting Started

              ### Quick Start (Automated):
              Run action: **complete_flow** - Full automated setup in one go!

              ### Manual Start:
              1. Run action: **full_analysis** - Analyze your CV vs job
              2. Run action: **auto_sprint_cycle** - Automated learning sprints

              ---

              *Generated by Ultimate Job Search Engine*
              """
                  Path("PROGRESS_REPORT.md").write_text(report_content)
                  print("\nüìã Workflow not initialized yet")
                  exit(0)
              
              state = engine.state
              score = state.get('current_score', 0)
              baseline = state.get('baseline_score', 0)
              improvement = score - baseline
              
              report_content = f"""# Ultimate Job Search Progress Report

              **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
              **Mode:** {state.get('mode', 'N/A').upper()}  
              **Action Performed:** ${{ github.event.inputs.action || 'scheduled' }}

              ---

              ## üìä Match Score Progress

              | Metric | Value |
              |--------|-------|
              | Baseline Score | {baseline}% |
              | Current Score | {score}% |
              | Improvement | +{improvement}% |
              | Target Score | {state.get('target_score', 90)}% |
              | Remaining | {state.get('target_score', 90) - score}% |

              {"üéâ **TARGET ACHIEVED!**" if score >= state.get('target_score', 90) else ""}

              ---

              ## üéØ Skills Mastered ({len(state.get('skills_mastered', []))})

              """
              
              if state.get('skills_mastered'):
                  for skill in state.get('skills_mastered', []):
                      report_content += f"- ‚úÖ {skill}\n"
              else:
                  report_content += "- No skills mastered yet\n"
              
              report_content += f"""

              ---

              ## üí° Automation Features

              ### Available Automated Actions:
              - **complete_flow** - Run entire lifecycle automatically (analysis ‚Üí plan ‚Üí materials)
              - **auto_sprint_cycle** - Automated sprint management (start ‚Üí log ‚Üí end)

              ### Manual Actions:
              - **full_analysis** - Analyze CV vs job
              - **start_sprint** - Begin new sprint
              - **log_daily** - Log daily progress
              - **end_sprint** - Complete sprint

              ---

              ## üóÇÔ∏è Projects Completed ({len(state.get('projects_completed', []))})

              """
              
              if state.get('projects_completed'):
                  for i, proj in enumerate(state.get('projects_completed', []), 1):
                      report_content += f"{i}. **{proj.get('goal', 'N/A')}**\n"
                      report_content += f"   - Skills: {', '.join(proj.get('skills', []))}\n\n"
              else:
                  report_content += "- No projects completed yet\n"
              
              report_content += """

              ---

              *Generated by Ultimate Job Search Engine - Your Path to the Perfect Job*
              """
              
              Path("PROGRESS_REPORT.md").write_text(report_content)
              
              print("\n‚úÖ Comprehensive report generated: PROGRESS_REPORT.md")
              
          except Exception as e:
              print(f"‚ùå Error: {e}")
              import traceback
              traceback.print_exc()
          PYTHON_EOF
      
      # =====================================================================
      # OPTION B: WORKFLOW CHAINING - Trigger next workflow automatically
      # =====================================================================
      
      - name: üîó Chain Next Workflow (Option B)
        if: |
          contains(github.event.inputs.options, 'chain_next') &&
          (steps.complete_flow.outputs.flow_completed == 'true' || 
           steps.auto_sprint.outputs.sprint_completed == 'true')
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const nextAction = '${{ steps.complete_flow.outputs.next_action || steps.auto_sprint.outputs.next_action }}';
            
            if (nextAction && nextAction !== 'null') {
              console.log(`üîó Triggering next workflow: ${nextAction}`);
              
              try {
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'ultime-job-engine.yml',
                  ref: 'main',
                  inputs: {
                    action: nextAction,
                    cv_path: '${{ github.event.inputs.cv_path }}',
                    job_path: '${{ github.event.inputs.job_path }}',
                    job_metadata: '${{ github.event.inputs.job_metadata }}',
                    sprint_data: '${{ github.event.inputs.sprint_data }}',
                    options: '${{ github.event.inputs.options }}',
                    email_to: '${{ github.event.inputs.email_to }}'
                  }
                });
                
                console.log('‚úÖ Next workflow triggered successfully!');
              } catch (error) {
                console.log(`‚ö†Ô∏è  Could not trigger next workflow: ${error.message}`);
              }
            } else {
              console.log('‚ÑπÔ∏è  No next action to chain');
            }
      
      # =====================================================================
      # SAVE STATE FOR NEXT RUN
      # =====================================================================
      
      - name: üíæ Save State to Artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ env.STATE_ARTIFACT }}
          path: ${{ env.DATA_DIR }}/
          retention-days: 90
          overwrite: true
      
      # =====================================================================
      # UPLOAD ALL ARTIFACTS
      # =====================================================================
      
      - name: üì§ Upload Progress Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: progress-report-${{ github.run_number }}
          path: PROGRESS_REPORT.md
          retention-days: 90
          if-no-files-found: warn
      
      - name: üì§ Upload Output Files
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: job-analysis-output-${{ github.run_number }}
          path: |
            output/
            batch_results/
          retention-days: 90
          if-no-files-found: ignore
      
      # =====================================================================
      # EMAIL NOTIFICATIONS
      # =====================================================================
      
      - name: üìß Send Email Notification
        if: |
          contains(github.event.inputs.options, 'send_email') &&
          (github.event.inputs.email_to != '')
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: |
            Job Search Update - Score: ${{ steps.init_engine.outputs.current_score }}%
          to: ${{ github.event.inputs.email_to }}
          from: Job Search Engine
          body: |
            Job Search Progress Update
            
            Action: ${{ github.event.inputs.action }}
            Current Score: ${{ steps.init_engine.outputs.current_score }}%
            Baseline Score: ${{ steps.init_engine.outputs.baseline_score }}%
            
            Check the full report in the Actions artifacts.
          
          attachments: PROGRESS_REPORT.md
        continue-on-error: true
      
      # =====================================================================
      # APPLICATION READY NOTIFICATION
      # =====================================================================
      
      - name: üéâ Application Ready Alert
        if: steps.quality_gates.outputs.application_ready == 'true'
        run: |
          echo ""
          echo "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì"
          echo "‚îÉ   üéâüéâüéâ CONGRATULATIONS! YOU'RE APPLICATION READY! üéâüéâüéâ      ‚îÉ"
          echo "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ"
          echo ""
          echo "‚úÖ All quality gates passed"
          echo "‚úÖ Match score target achieved"
          echo "‚úÖ Skills mastered and validated"
          echo "‚úÖ Projects completed"
          echo ""
          echo "üöÄ START APPLYING TO JOBS TODAY!"
          echo ""
      
      # =====================================================================
      # FINAL STATUS SUMMARY
      # =====================================================================
      
      - name: üìã Final Status & Summary
        if: always()
        run: |
          echo ""
          echo "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì"
          echo "‚îÉ              ‚úÖ Ultimate Job Search Engine Complete              ‚îÉ"
          echo "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ"
          echo ""
          echo "üìä Run Details:"
          echo "   ‚Ä¢ Action: ${{ github.event.inputs.action || 'scheduled' }}"
          echo "   ‚Ä¢ Workflow: ${{ github.workflow }}"
          echo "   ‚Ä¢ Run Number: ${{ github.run_number }}"
          echo ""
          echo "üöÄ Available Automation Features:"
          echo "   ‚Ä¢ complete_flow - Full lifecycle automation"
          echo "   ‚Ä¢ auto_sprint_cycle - Automated sprint management"
          echo "   ‚Ä¢ chain_next (option) - Auto-trigger next workflow"
          echo ""
